{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final- k-fold_Model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalihaUCF/Machine-Learning-Course-Assignments-Spring-2019/blob/master/Assignment%202/Final_k_fold_Model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "amevUdJWUBwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading CIFAR-10 dataset\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "\n",
        "#creating train,validate and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images1, val_images1, train_labels1, val_labels1 = train_test_split(train_images,train_labels,test_size=0.0002,stratify=train_labels)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_images1.shape)\n",
        "print(val_images1.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels1.shape)\n",
        "\n",
        "\n",
        "for i in range(0,50):\n",
        "  print(train_labels[i])\n",
        "\n",
        "def k_fold_dataset(i,train_images1,train_labels1):\n",
        "  val_index_a=i*10000\n",
        "  val_index_b=val_index_a+10000\n",
        "  \n",
        "  #splitting train images into train and val set\n",
        "  #val set\n",
        "  X_val=train_images1[val_index_a:val_index_b]\n",
        "  y_val=train_labels1[val_index_a:val_index_b]\n",
        "  \n",
        "  #train set\n",
        "  X_train=np.append(train_images1[0:val_index_a],train_images1[val_index_b:50000],axis=0)\n",
        "  y_train=np.append(train_labels1[0:val_index_a],train_labels1[val_index_b:50000],axis=0)\n",
        "  \n",
        "  \n",
        "  return X_train,y_train,X_val,y_val\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFAElkl0TBiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 30\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "#using our best model with k-fold\n",
        "def train_model1(i,X_train,y_train,X_val,y_val,test_images,test_labels):\n",
        "  \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                   input_shape=X_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        " \n",
        "\n",
        "  #using ADAM\n",
        "\n",
        "  Adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "\n",
        "  # Let's train our best model using Adam\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=Adam,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      history=model.fit(X_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(X_val, y_val),\n",
        "                shuffle=True)\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "       datagen = ImageDataGenerator(\n",
        "      rotation_range=15,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True)\n",
        "    \n",
        "      datagen.fit(X_train)\n",
        "\n",
        "      \n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      model.fit_generator(datagen.flow(X_train, y_train,\n",
        "                                       batch_size=batch_size),\n",
        "                          epochs=epochs,steps_per_epoch=100,validation_steps=50,\n",
        "                          validation_data=(X_val, y_val))\n",
        "\n",
        "  \n",
        "  \n",
        "  from sklearn.metrics import classification_report, confusion_matrix\n",
        "  import os\n",
        "  from keras.models import load_model\n",
        "\n",
        "\n",
        "  y_pred=model.predict(test_images) \n",
        "  y_pred = [np.argmax(entry) for entry in y_pred]\n",
        "  y_true = [np.argmax(entry) for entry in test_labels]\n",
        "\n",
        "  print('Confusion Matrix\\n\\n')\n",
        "  print(confusion_matrix(y_true, y_pred))  \n",
        "\n",
        "  print(classification_report(y_pred,y_true))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oW-y8ZLCkoJ-",
        "colab_type": "code",
        "outputId": "406657ad-a216-430d-9e42-ad6e9ed3725b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8435
        }
      },
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "num_classes=10\n",
        "# Convert class vectors to binary class matrices.\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "\n",
        "for a in range(0,5):\n",
        "    X_train,y_train,X_val,y_val=k_fold_dataset(a,train_images1,train_labels1)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_val = X_val.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_val /= 255\n",
        "    \n",
        "    \n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_val=keras.utils.to_categorical(y_val, num_classes)\n",
        "    \n",
        "    print(train_images1.shape)\n",
        "    print(X_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(test_images.shape)  \n",
        "    print(y_val.shape)\n",
        "    \n",
        "    train_model1(a,X_train,y_train,X_val,y_val,test_images, test_labels)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49990, 32, 32, 3)\n",
            "(39990, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Not using data augmentation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 39990 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "39990/39990 [==============================] - 35s 865us/step - loss: 1.8311 - acc: 0.3266 - val_loss: 1.5295 - val_acc: 0.4526\n",
            "Epoch 2/30\n",
            "39990/39990 [==============================] - 31s 770us/step - loss: 1.4999 - acc: 0.4556 - val_loss: 1.3944 - val_acc: 0.5027\n",
            "Epoch 3/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 1.3786 - acc: 0.5043 - val_loss: 1.2788 - val_acc: 0.5439\n",
            "Epoch 4/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 1.2862 - acc: 0.5389 - val_loss: 1.1894 - val_acc: 0.5797\n",
            "Epoch 5/30\n",
            "39990/39990 [==============================] - 31s 770us/step - loss: 1.2116 - acc: 0.5683 - val_loss: 1.1264 - val_acc: 0.6002\n",
            "Epoch 6/30\n",
            "39990/39990 [==============================] - 31s 766us/step - loss: 1.1447 - acc: 0.5964 - val_loss: 1.0751 - val_acc: 0.6254\n",
            "Epoch 7/30\n",
            "39990/39990 [==============================] - 31s 771us/step - loss: 1.0839 - acc: 0.6196 - val_loss: 1.0217 - val_acc: 0.6388\n",
            "Epoch 8/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 1.0281 - acc: 0.6393 - val_loss: 0.9899 - val_acc: 0.6532\n",
            "Epoch 9/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.9827 - acc: 0.6560 - val_loss: 0.9334 - val_acc: 0.6729\n",
            "Epoch 10/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.9411 - acc: 0.6699 - val_loss: 0.9169 - val_acc: 0.6783\n",
            "Epoch 11/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 0.9069 - acc: 0.6827 - val_loss: 0.8566 - val_acc: 0.7007\n",
            "Epoch 12/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.8701 - acc: 0.6964 - val_loss: 0.8444 - val_acc: 0.7077\n",
            "Epoch 13/30\n",
            "39990/39990 [==============================] - 31s 769us/step - loss: 0.8361 - acc: 0.7074 - val_loss: 0.8231 - val_acc: 0.7149\n",
            "Epoch 14/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.8115 - acc: 0.7177 - val_loss: 0.7802 - val_acc: 0.7297\n",
            "Epoch 15/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.7803 - acc: 0.7267 - val_loss: 0.7793 - val_acc: 0.7271\n",
            "Epoch 16/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.7559 - acc: 0.7361 - val_loss: 0.7602 - val_acc: 0.7346\n",
            "Epoch 17/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 0.7332 - acc: 0.7432 - val_loss: 0.7291 - val_acc: 0.7447\n",
            "Epoch 18/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 0.7095 - acc: 0.7518 - val_loss: 0.7386 - val_acc: 0.7415\n",
            "Epoch 19/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 0.6882 - acc: 0.7593 - val_loss: 0.7113 - val_acc: 0.7547\n",
            "Epoch 20/30\n",
            "39990/39990 [==============================] - 31s 771us/step - loss: 0.6635 - acc: 0.7669 - val_loss: 0.6948 - val_acc: 0.7584\n",
            "Epoch 21/30\n",
            "39990/39990 [==============================] - 31s 767us/step - loss: 0.6473 - acc: 0.7739 - val_loss: 0.6889 - val_acc: 0.7589\n",
            "Epoch 22/30\n",
            "39990/39990 [==============================] - 31s 766us/step - loss: 0.6266 - acc: 0.7798 - val_loss: 0.6711 - val_acc: 0.7673\n",
            "Epoch 23/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.6071 - acc: 0.7873 - val_loss: 0.6700 - val_acc: 0.7652\n",
            "Epoch 24/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.5876 - acc: 0.7940 - val_loss: 0.6604 - val_acc: 0.7693\n",
            "Epoch 25/30\n",
            "39990/39990 [==============================] - 31s 771us/step - loss: 0.5726 - acc: 0.8008 - val_loss: 0.6513 - val_acc: 0.7700\n",
            "Epoch 26/30\n",
            "39990/39990 [==============================] - 31s 767us/step - loss: 0.5556 - acc: 0.8050 - val_loss: 0.6818 - val_acc: 0.7669\n",
            "Epoch 27/30\n",
            "39990/39990 [==============================] - 31s 769us/step - loss: 0.5358 - acc: 0.8115 - val_loss: 0.6536 - val_acc: 0.7728\n",
            "Epoch 28/30\n",
            "39990/39990 [==============================] - 31s 770us/step - loss: 0.5260 - acc: 0.8154 - val_loss: 0.6477 - val_acc: 0.7765\n",
            "Epoch 29/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.5112 - acc: 0.8179 - val_loss: 0.6504 - val_acc: 0.7758\n",
            "Epoch 30/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.4944 - acc: 0.8253 - val_loss: 0.6444 - val_acc: 0.7808\n",
            "Confusion Matrix\n",
            "\n",
            "\n",
            "[[844  24   1  17   1   7   0  13  42  51]\n",
            " [ 21 851   0   2   0   4   0   2  32  88]\n",
            " [168   7 315  98  19 220  12  78  38  45]\n",
            " [ 60  20   9 410  12 302   5  62  38  82]\n",
            " [ 81  13  32 107 284 192  15 204  34  38]\n",
            " [ 28   8   6  93   5 750   5  59   9  37]\n",
            " [ 42  19  17 167   7 140 474  35  50  49]\n",
            " [ 28   8   1  17   7  69   0 808   3  59]\n",
            " [ 98  22   0   8   0   6   0   4 803  59]\n",
            " [ 25  35   1   2   0   2   1   5  17 912]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.61      0.70      1395\n",
            "           1       0.85      0.85      0.85      1007\n",
            "           2       0.32      0.82      0.46       382\n",
            "           3       0.41      0.45      0.43       921\n",
            "           4       0.28      0.85      0.43       335\n",
            "           5       0.75      0.44      0.56      1692\n",
            "           6       0.47      0.93      0.63       512\n",
            "           7       0.81      0.64      0.71      1270\n",
            "           8       0.80      0.75      0.78      1066\n",
            "           9       0.91      0.64      0.75      1420\n",
            "\n",
            "   micro avg       0.65      0.65      0.65     10000\n",
            "   macro avg       0.65      0.70      0.63     10000\n",
            "weighted avg       0.73      0.65      0.66     10000\n",
            "\n",
            "(49990, 32, 32, 3)\n",
            "(39990, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "Not using data augmentation.\n",
            "Train on 39990 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "39990/39990 [==============================] - 33s 813us/step - loss: 1.8392 - acc: 0.3267 - val_loss: 1.5135 - val_acc: 0.4507\n",
            "Epoch 2/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 1.4908 - acc: 0.4590 - val_loss: 1.3666 - val_acc: 0.5075\n",
            "Epoch 3/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 1.3635 - acc: 0.5074 - val_loss: 1.2575 - val_acc: 0.5521\n",
            "Epoch 4/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 1.2780 - acc: 0.5404 - val_loss: 1.1750 - val_acc: 0.5834\n",
            "Epoch 5/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 1.1975 - acc: 0.5728 - val_loss: 1.1245 - val_acc: 0.6008\n",
            "Epoch 6/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 1.1259 - acc: 0.6031 - val_loss: 1.0553 - val_acc: 0.6281\n",
            "Epoch 7/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 1.0715 - acc: 0.6209 - val_loss: 0.9981 - val_acc: 0.6418\n",
            "Epoch 8/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 1.0126 - acc: 0.6429 - val_loss: 0.9848 - val_acc: 0.6490\n",
            "Epoch 9/30\n",
            "39990/39990 [==============================] - 31s 782us/step - loss: 0.9705 - acc: 0.6582 - val_loss: 0.9298 - val_acc: 0.6791\n",
            "Epoch 10/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.9252 - acc: 0.6756 - val_loss: 0.9278 - val_acc: 0.6743\n",
            "Epoch 11/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.8918 - acc: 0.6877 - val_loss: 0.8659 - val_acc: 0.6976\n",
            "Epoch 12/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.8575 - acc: 0.6985 - val_loss: 0.8682 - val_acc: 0.6960\n",
            "Epoch 13/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 0.8292 - acc: 0.7099 - val_loss: 0.8400 - val_acc: 0.7084\n",
            "Epoch 14/30\n",
            "39990/39990 [==============================] - 31s 771us/step - loss: 0.7992 - acc: 0.7186 - val_loss: 0.8076 - val_acc: 0.7150\n",
            "Epoch 15/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.7744 - acc: 0.7256 - val_loss: 0.7827 - val_acc: 0.7325\n",
            "Epoch 16/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 0.7488 - acc: 0.7380 - val_loss: 0.7698 - val_acc: 0.7309\n",
            "Epoch 17/30\n",
            "39990/39990 [==============================] - 31s 782us/step - loss: 0.7218 - acc: 0.7467 - val_loss: 0.7641 - val_acc: 0.7339\n",
            "Epoch 18/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 0.6979 - acc: 0.7546 - val_loss: 0.7347 - val_acc: 0.7446\n",
            "Epoch 19/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.6815 - acc: 0.7605 - val_loss: 0.7374 - val_acc: 0.7434\n",
            "Epoch 20/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.6621 - acc: 0.7677 - val_loss: 0.7215 - val_acc: 0.7480\n",
            "Epoch 21/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 0.6445 - acc: 0.7779 - val_loss: 0.7026 - val_acc: 0.7601\n",
            "Epoch 22/30\n",
            "39990/39990 [==============================] - 31s 772us/step - loss: 0.6211 - acc: 0.7809 - val_loss: 0.7249 - val_acc: 0.7511\n",
            "Epoch 23/30\n",
            "39990/39990 [==============================] - 31s 783us/step - loss: 0.6081 - acc: 0.7864 - val_loss: 0.6969 - val_acc: 0.7638\n",
            "Epoch 24/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 0.5840 - acc: 0.7961 - val_loss: 0.6922 - val_acc: 0.7624\n",
            "Epoch 25/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.5739 - acc: 0.7978 - val_loss: 0.6909 - val_acc: 0.7663\n",
            "Epoch 26/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.5571 - acc: 0.8044 - val_loss: 0.6680 - val_acc: 0.7667\n",
            "Epoch 27/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.5417 - acc: 0.8082 - val_loss: 0.6806 - val_acc: 0.7635\n",
            "Epoch 28/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 0.5268 - acc: 0.8137 - val_loss: 0.6770 - val_acc: 0.7714\n",
            "Epoch 29/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 0.5098 - acc: 0.8201 - val_loss: 0.6644 - val_acc: 0.7756\n",
            "Epoch 30/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.4934 - acc: 0.8249 - val_loss: 0.6579 - val_acc: 0.7742\n",
            "Confusion Matrix\n",
            "\n",
            "\n",
            "[[888  25   2   5   1   2   1  11  32  33]\n",
            " [ 21 894   0   0   0   3   0   1  13  68]\n",
            " [206  30 338  37  33 118  19 128  34  57]\n",
            " [ 84  30  16 311  13 258  19 138  37  94]\n",
            " [109  23  16  42 368  79  22 260  26  55]\n",
            " [ 44  11   4  71  13 669   9 133  11  35]\n",
            " [ 41  46  16  49  17  72 597  35  44  83]\n",
            " [ 31  13   2   9   3  39   0 840   6  57]\n",
            " [123  42   0   1   0   7   0   4 779  44]\n",
            " [ 31  90   0   1   0   0   1   9  11 857]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.56      0.69      1578\n",
            "           1       0.89      0.74      0.81      1204\n",
            "           2       0.34      0.86      0.48       394\n",
            "           3       0.31      0.59      0.41       526\n",
            "           4       0.37      0.82      0.51       448\n",
            "           5       0.67      0.54      0.60      1247\n",
            "           6       0.60      0.89      0.72       668\n",
            "           7       0.84      0.54      0.66      1559\n",
            "           8       0.78      0.78      0.78       993\n",
            "           9       0.86      0.62      0.72      1383\n",
            "\n",
            "   micro avg       0.65      0.65      0.65     10000\n",
            "   macro avg       0.65      0.69      0.64     10000\n",
            "weighted avg       0.74      0.65      0.67     10000\n",
            "\n",
            "(49990, 32, 32, 3)\n",
            "(39990, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "Not using data augmentation.\n",
            "Train on 39990 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "39990/39990 [==============================] - 33s 832us/step - loss: 1.8048 - acc: 0.3344 - val_loss: 1.5207 - val_acc: 0.4449\n",
            "Epoch 2/30\n",
            "39990/39990 [==============================] - 31s 770us/step - loss: 1.5043 - acc: 0.4515 - val_loss: 1.3668 - val_acc: 0.5055\n",
            "Epoch 3/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 1.3845 - acc: 0.5024 - val_loss: 1.2939 - val_acc: 0.5349\n",
            "Epoch 4/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 1.3057 - acc: 0.5338 - val_loss: 1.2338 - val_acc: 0.5607\n",
            "Epoch 5/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 1.2385 - acc: 0.5602 - val_loss: 1.1232 - val_acc: 0.5998\n",
            "Epoch 6/30\n",
            "39990/39990 [==============================] - 30s 763us/step - loss: 1.1757 - acc: 0.5852 - val_loss: 1.0761 - val_acc: 0.6235\n",
            "Epoch 7/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 1.1210 - acc: 0.6038 - val_loss: 1.0518 - val_acc: 0.6269\n",
            "Epoch 8/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 1.0757 - acc: 0.6230 - val_loss: 0.9946 - val_acc: 0.6494\n",
            "Epoch 9/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 1.0304 - acc: 0.6363 - val_loss: 0.9391 - val_acc: 0.6745\n",
            "Epoch 10/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 0.9860 - acc: 0.6499 - val_loss: 0.9196 - val_acc: 0.6724\n",
            "Epoch 11/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.9486 - acc: 0.6658 - val_loss: 0.8891 - val_acc: 0.6947\n",
            "Epoch 12/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.9147 - acc: 0.6795 - val_loss: 0.8595 - val_acc: 0.7064\n",
            "Epoch 13/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 0.8826 - acc: 0.6910 - val_loss: 0.8197 - val_acc: 0.7184\n",
            "Epoch 14/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.8511 - acc: 0.7026 - val_loss: 0.8158 - val_acc: 0.7201\n",
            "Epoch 15/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.8184 - acc: 0.7103 - val_loss: 0.7821 - val_acc: 0.7289\n",
            "Epoch 16/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.7955 - acc: 0.7209 - val_loss: 0.7862 - val_acc: 0.7242\n",
            "Epoch 17/30\n",
            "39990/39990 [==============================] - 31s 779us/step - loss: 0.7718 - acc: 0.7272 - val_loss: 0.7756 - val_acc: 0.7304\n",
            "Epoch 18/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.7459 - acc: 0.7380 - val_loss: 0.7526 - val_acc: 0.7413\n",
            "Epoch 19/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 0.7247 - acc: 0.7453 - val_loss: 0.7318 - val_acc: 0.7483\n",
            "Epoch 20/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.7023 - acc: 0.7543 - val_loss: 0.7208 - val_acc: 0.7486\n",
            "Epoch 21/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.6800 - acc: 0.7648 - val_loss: 0.7101 - val_acc: 0.7535\n",
            "Epoch 22/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.6628 - acc: 0.7670 - val_loss: 0.6910 - val_acc: 0.7602\n",
            "Epoch 23/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.6430 - acc: 0.7741 - val_loss: 0.6933 - val_acc: 0.7652\n",
            "Epoch 24/30\n",
            "39990/39990 [==============================] - 31s 773us/step - loss: 0.6269 - acc: 0.7802 - val_loss: 0.6739 - val_acc: 0.7687\n",
            "Epoch 25/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.6080 - acc: 0.7872 - val_loss: 0.6747 - val_acc: 0.7670\n",
            "Epoch 26/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 0.5907 - acc: 0.7923 - val_loss: 0.6758 - val_acc: 0.7669\n",
            "Epoch 27/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.5740 - acc: 0.7971 - val_loss: 0.6674 - val_acc: 0.7663\n",
            "Epoch 28/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.5570 - acc: 0.8034 - val_loss: 0.6856 - val_acc: 0.7630\n",
            "Epoch 29/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 0.5449 - acc: 0.8078 - val_loss: 0.6535 - val_acc: 0.7749\n",
            "Epoch 30/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.5266 - acc: 0.8144 - val_loss: 0.6604 - val_acc: 0.7739\n",
            "Confusion Matrix\n",
            "\n",
            "\n",
            "[[891  32   5   3   3   5   1  11  27  22]\n",
            " [ 24 889   0   1   0   2   0   0  26  58]\n",
            " [309  29 226  30  23 163  31 115  41  33]\n",
            " [172  33   6 215  13 259  14 130  76  82]\n",
            " [210  35  16  17 230 126  35 254  33  44]\n",
            " [ 62  14   4  43  10 686   1 126  17  37]\n",
            " [118  68   7  33   2  71 489  45  92  75]\n",
            " [ 53  11   1   1   7  46   0 837   3  41]\n",
            " [221  47   0   1   1   3   0  11 670  46]\n",
            " [ 63  77   1   0   0   3   0  10   5 841]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.42      0.57      2123\n",
            "           1       0.89      0.72      0.80      1235\n",
            "           2       0.23      0.85      0.36       266\n",
            "           3       0.21      0.62      0.32       344\n",
            "           4       0.23      0.80      0.36       289\n",
            "           5       0.69      0.50      0.58      1364\n",
            "           6       0.49      0.86      0.62       571\n",
            "           7       0.84      0.54      0.66      1539\n",
            "           8       0.67      0.68      0.67       990\n",
            "           9       0.84      0.66      0.74      1279\n",
            "\n",
            "   micro avg       0.60      0.60      0.60     10000\n",
            "   macro avg       0.60      0.66      0.57     10000\n",
            "weighted avg       0.74      0.60      0.63     10000\n",
            "\n",
            "(49990, 32, 32, 3)\n",
            "(39990, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "Not using data augmentation.\n",
            "Train on 39990 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "39990/39990 [==============================] - 33s 822us/step - loss: 1.7942 - acc: 0.3410 - val_loss: 1.5235 - val_acc: 0.4496\n",
            "Epoch 2/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 1.4942 - acc: 0.4591 - val_loss: 1.3519 - val_acc: 0.5191\n",
            "Epoch 3/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 1.3645 - acc: 0.5118 - val_loss: 1.2391 - val_acc: 0.5637\n",
            "Epoch 4/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 1.2717 - acc: 0.5492 - val_loss: 1.1593 - val_acc: 0.5933\n",
            "Epoch 5/30\n",
            "39990/39990 [==============================] - 31s 774us/step - loss: 1.2007 - acc: 0.5738 - val_loss: 1.1184 - val_acc: 0.6091\n",
            "Epoch 6/30\n",
            "39990/39990 [==============================] - 31s 775us/step - loss: 1.1340 - acc: 0.5993 - val_loss: 1.0431 - val_acc: 0.6377\n",
            "Epoch 7/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 1.0752 - acc: 0.6198 - val_loss: 1.0072 - val_acc: 0.6508\n",
            "Epoch 8/30\n",
            "39990/39990 [==============================] - 31s 771us/step - loss: 1.0255 - acc: 0.6367 - val_loss: 0.9621 - val_acc: 0.6659\n",
            "Epoch 9/30\n",
            "39990/39990 [==============================] - 31s 783us/step - loss: 0.9839 - acc: 0.6557 - val_loss: 0.9239 - val_acc: 0.6784\n",
            "Epoch 10/30\n",
            "39990/39990 [==============================] - 31s 781us/step - loss: 0.9474 - acc: 0.6651 - val_loss: 0.8823 - val_acc: 0.6980\n",
            "Epoch 11/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 0.9168 - acc: 0.6780 - val_loss: 0.8784 - val_acc: 0.6980\n",
            "Epoch 12/30\n",
            "39990/39990 [==============================] - 31s 781us/step - loss: 0.8835 - acc: 0.6901 - val_loss: 0.8398 - val_acc: 0.7109\n",
            "Epoch 13/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.8516 - acc: 0.7018 - val_loss: 0.8232 - val_acc: 0.7162\n",
            "Epoch 14/30\n",
            "39990/39990 [==============================] - 31s 780us/step - loss: 0.8225 - acc: 0.7112 - val_loss: 0.7992 - val_acc: 0.7248\n",
            "Epoch 15/30\n",
            "39990/39990 [==============================] - 31s 777us/step - loss: 0.7984 - acc: 0.7185 - val_loss: 0.7844 - val_acc: 0.7287\n",
            "Epoch 16/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 0.7691 - acc: 0.7298 - val_loss: 0.7770 - val_acc: 0.7323\n",
            "Epoch 17/30\n",
            "39990/39990 [==============================] - 31s 778us/step - loss: 0.7512 - acc: 0.7385 - val_loss: 0.7715 - val_acc: 0.7371\n",
            "Epoch 18/30\n",
            "39990/39990 [==============================] - 31s 776us/step - loss: 0.7297 - acc: 0.7430 - val_loss: 0.7464 - val_acc: 0.7416\n",
            "Epoch 19/30\n",
            "39990/39990 [==============================] - 32s 804us/step - loss: 0.7056 - acc: 0.7534 - val_loss: 0.7467 - val_acc: 0.7455\n",
            "Epoch 20/30\n",
            "39990/39990 [==============================] - 38s 956us/step - loss: 0.6853 - acc: 0.7606 - val_loss: 0.7522 - val_acc: 0.7390\n",
            "Epoch 21/30\n",
            "39990/39990 [==============================] - 32s 789us/step - loss: 0.6678 - acc: 0.7669 - val_loss: 0.7431 - val_acc: 0.7450\n",
            "Epoch 22/30\n",
            "39990/39990 [==============================] - 32s 800us/step - loss: 0.6440 - acc: 0.7740 - val_loss: 0.7085 - val_acc: 0.7572\n",
            "Epoch 23/30\n",
            "39990/39990 [==============================] - 32s 798us/step - loss: 0.6299 - acc: 0.7790 - val_loss: 0.7015 - val_acc: 0.7575\n",
            "Epoch 24/30\n",
            "39990/39990 [==============================] - 32s 801us/step - loss: 0.6095 - acc: 0.7866 - val_loss: 0.7015 - val_acc: 0.7592\n",
            "Epoch 25/30\n",
            "39990/39990 [==============================] - 32s 788us/step - loss: 0.5993 - acc: 0.7879 - val_loss: 0.6868 - val_acc: 0.7678\n",
            "Epoch 26/30\n",
            "39990/39990 [==============================] - 32s 795us/step - loss: 0.5800 - acc: 0.7965 - val_loss: 0.6992 - val_acc: 0.7600\n",
            "Epoch 27/30\n",
            "39990/39990 [==============================] - 32s 799us/step - loss: 0.5638 - acc: 0.8024 - val_loss: 0.6760 - val_acc: 0.7700\n",
            "Epoch 28/30\n",
            "39990/39990 [==============================] - 32s 795us/step - loss: 0.5432 - acc: 0.8092 - val_loss: 0.7045 - val_acc: 0.7621\n",
            "Epoch 29/30\n",
            "39990/39990 [==============================] - 32s 791us/step - loss: 0.5305 - acc: 0.8131 - val_loss: 0.6743 - val_acc: 0.7676\n",
            "Epoch 30/30\n",
            "39990/39990 [==============================] - 31s 785us/step - loss: 0.5220 - acc: 0.8160 - val_loss: 0.6773 - val_acc: 0.7702\n",
            "Confusion Matrix\n",
            "\n",
            "\n",
            "[[864  16   3  20   1   6   1  14  42  33]\n",
            " [ 22 861   0   5   0   2   2   1  30  77]\n",
            " [161  17 274 154  27 148  17 128  37  37]\n",
            " [ 52  20   7 478   5 246   8  95  35  54]\n",
            " [ 78  11   8 124 279 124  18 280  29  49]\n",
            " [ 29   6   3 121   4 706   8  92   7  24]\n",
            " [ 36  21  10 142   4 106 532  54  38  57]\n",
            " [ 34   6   0  17   3  45   0 846   4  45]\n",
            " [ 97  25   0  10   1   6   0   4 821  36]\n",
            " [ 31  73   1  11   0   1   1  11  24 847]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.62      0.72      1404\n",
            "           1       0.86      0.82      0.84      1056\n",
            "           2       0.27      0.90      0.42       306\n",
            "           3       0.48      0.44      0.46      1082\n",
            "           4       0.28      0.86      0.42       324\n",
            "           5       0.71      0.51      0.59      1390\n",
            "           6       0.53      0.91      0.67       587\n",
            "           7       0.85      0.55      0.67      1525\n",
            "           8       0.82      0.77      0.79      1067\n",
            "           9       0.85      0.67      0.75      1259\n",
            "\n",
            "   micro avg       0.65      0.65      0.65     10000\n",
            "   macro avg       0.65      0.70      0.63     10000\n",
            "weighted avg       0.73      0.65      0.67     10000\n",
            "\n",
            "(49990, 32, 32, 3)\n",
            "(40000, 32, 32, 3)\n",
            "(9990, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(9990, 10)\n",
            "Not using data augmentation.\n",
            "Train on 40000 samples, validate on 9990 samples\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 34s 843us/step - loss: 1.8024 - acc: 0.3345 - val_loss: 1.6157 - val_acc: 0.4240\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 32s 798us/step - loss: 1.4813 - acc: 0.4642 - val_loss: 1.3505 - val_acc: 0.5140\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 32s 807us/step - loss: 1.3500 - acc: 0.5144 - val_loss: 1.2469 - val_acc: 0.5601\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 32s 803us/step - loss: 1.2543 - acc: 0.5549 - val_loss: 1.1589 - val_acc: 0.5941\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 32s 805us/step - loss: 1.1727 - acc: 0.5857 - val_loss: 1.0892 - val_acc: 0.6161\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 32s 799us/step - loss: 1.1018 - acc: 0.6110 - val_loss: 1.0282 - val_acc: 0.6416\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 32s 791us/step - loss: 1.0469 - acc: 0.6318 - val_loss: 0.9847 - val_acc: 0.6537\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 31s 787us/step - loss: 0.9969 - acc: 0.6514 - val_loss: 0.9447 - val_acc: 0.6703\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 32s 809us/step - loss: 0.9496 - acc: 0.6689 - val_loss: 0.8945 - val_acc: 0.6895\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 32s 812us/step - loss: 0.9150 - acc: 0.6803 - val_loss: 0.8742 - val_acc: 0.6941\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 32s 805us/step - loss: 0.8786 - acc: 0.6943 - val_loss: 0.8524 - val_acc: 0.7045\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 32s 799us/step - loss: 0.8420 - acc: 0.7039 - val_loss: 0.8073 - val_acc: 0.7179\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 32s 806us/step - loss: 0.8158 - acc: 0.7150 - val_loss: 0.7930 - val_acc: 0.7227\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 32s 809us/step - loss: 0.7847 - acc: 0.7278 - val_loss: 0.7785 - val_acc: 0.7288\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 32s 804us/step - loss: 0.7565 - acc: 0.7347 - val_loss: 0.7636 - val_acc: 0.7366\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 32s 800us/step - loss: 0.7378 - acc: 0.7420 - val_loss: 0.7494 - val_acc: 0.7390\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 32s 797us/step - loss: 0.7126 - acc: 0.7510 - val_loss: 0.7285 - val_acc: 0.7469\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 32s 808us/step - loss: 0.6877 - acc: 0.7583 - val_loss: 0.7177 - val_acc: 0.7499\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 32s 804us/step - loss: 0.6721 - acc: 0.7668 - val_loss: 0.7115 - val_acc: 0.7524\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 32s 811us/step - loss: 0.6457 - acc: 0.7747 - val_loss: 0.6992 - val_acc: 0.7572\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 32s 803us/step - loss: 0.6333 - acc: 0.7782 - val_loss: 0.7002 - val_acc: 0.7542\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 32s 799us/step - loss: 0.6151 - acc: 0.7850 - val_loss: 0.6828 - val_acc: 0.7639\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 32s 798us/step - loss: 0.5944 - acc: 0.7911 - val_loss: 0.6951 - val_acc: 0.7590\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 32s 800us/step - loss: 0.5837 - acc: 0.7957 - val_loss: 0.6820 - val_acc: 0.7648\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 32s 806us/step - loss: 0.5616 - acc: 0.8026 - val_loss: 0.6577 - val_acc: 0.7734\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 32s 802us/step - loss: 0.5473 - acc: 0.8084 - val_loss: 0.6648 - val_acc: 0.7710\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 32s 806us/step - loss: 0.5308 - acc: 0.8153 - val_loss: 0.6486 - val_acc: 0.7764\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 32s 802us/step - loss: 0.5175 - acc: 0.8189 - val_loss: 0.6704 - val_acc: 0.7652\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 32s 806us/step - loss: 0.5006 - acc: 0.8230 - val_loss: 0.6650 - val_acc: 0.7731\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 32s 805us/step - loss: 0.4921 - acc: 0.8266 - val_loss: 0.6455 - val_acc: 0.7832\n",
            "Confusion Matrix\n",
            "\n",
            "\n",
            "[[886  13   1  15   1   2   0   5  28  49]\n",
            " [ 32 837   0   5   0   1   1   1  32  91]\n",
            " [265  16 236 151   9  83  21 110  56  53]\n",
            " [ 81  20   4 550  13 104  12  79  60  77]\n",
            " [136  13  17 154 292  50  27 211  39  61]\n",
            " [ 54  12   2 229  11 508   6 112  20  46]\n",
            " [ 52  22  11 135   8  33 567  35  75  62]\n",
            " [ 50   7   3  24  11  27   0 790  10  78]\n",
            " [172  25   0   9   0   1   0   0 736  57]\n",
            " [ 45  54   0   3   0   0   0   3  14 881]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.50      0.64      1773\n",
            "           1       0.84      0.82      0.83      1019\n",
            "           2       0.24      0.86      0.37       274\n",
            "           3       0.55      0.43      0.48      1275\n",
            "           4       0.29      0.85      0.43       345\n",
            "           5       0.51      0.63      0.56       809\n",
            "           6       0.57      0.89      0.69       634\n",
            "           7       0.79      0.59      0.67      1346\n",
            "           8       0.74      0.69      0.71      1070\n",
            "           9       0.88      0.61      0.72      1455\n",
            "\n",
            "   micro avg       0.63      0.63      0.63     10000\n",
            "   macro avg       0.63      0.69      0.61     10000\n",
            "weighted avg       0.72      0.63      0.65     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmEAMkY60Q3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# average of k-fold accuracy as seen above in the classification reports\n",
        "\n",
        "k1=65\n",
        "k2=65\n",
        "k3=60\n",
        "k4=65\n",
        "k5=63\n",
        "\n",
        "\n",
        "#Saving the model as an h5 file\n",
        "\n",
        "good_model='adam_dropout_k-fold_out.h5'\n",
        "model.save(good_model)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "with open(good_model, 'r') as f:\n",
        "  files.download(good_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uPjcp4x2CxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ce3a9454-05e4-4ba6-ed96-1e84ff80e90b"
      },
      "cell_type": "code",
      "source": [
        "#printing the f1, microavg scores per fold\n",
        "\n",
        "print('k1 Test accuracy : ', k1,'%')\n",
        "print('k2 Test accuracy : ', k2,'%')\n",
        "print('k3 Test accuracy : ', k3,'%')\n",
        "print('k4 Test accuracy : ', k4,'%')\n",
        "print('k5 Test accuracy : ', k5,'%')\n",
        "\n",
        "avg=(k1+k2+k3+k4+k5)/5\n",
        "print('\\n')\n",
        "print('Avg score using k fold validation is ' ,avg,'% after 30 epochs for each training and val set')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k1 Test accuracy :  65 %\n",
            "k2 Test accuracy :  65 %\n",
            "k3 Test accuracy :  60 %\n",
            "k4 Test accuracy :  65 %\n",
            "k5 Test accuracy :  63 %\n",
            "\n",
            "\n",
            "Avg score using k fold validation is  63.6 % after 30 epochs for each training and val set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "72cyo6cntUGx",
        "colab_type": "code",
        "outputId": "662d704f-2f50-4b8c-de9f-5ecafe5a03a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adam_dropout_hold_out.h5  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}