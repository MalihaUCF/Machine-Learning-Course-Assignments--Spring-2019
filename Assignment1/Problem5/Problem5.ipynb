{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalihaUCF/Machine-Learning-Course-Assignments--Spring-2019/blob/master/Assignment1/Problem5/Problem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e_SJZZVtVlAS",
        "colab_type": "code",
        "outputId": "295758ea-a392-42a8-b4c4-def1d4068a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature Engineering \n",
        "# Extending my solution to problem 4\n",
        "# Loading MNIST \n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(train_images_original,train_labels_original),(test_images_original,test_labels_original)=mnist.load_data()  \n",
        "\n",
        "print('Training Data Shape',train_images_original.shape)\n",
        "print('Test Data Shape',test_images_original.shape)\n",
        "print('The train and test labels look like this,' ,train_labels_original.shape,test_labels_original.shape)\n",
        "\n",
        "train_images = train_images_original.reshape(60000, 28*28)  #reshaped\n",
        "test_images = test_images_original.reshape(10000, 28*28) \n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Shape (60000, 28, 28)\n",
            "Test Data Shape (10000, 28, 28)\n",
            "The train and test labels look like this, (60000,) (10000,)\n",
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x9gfVxPZJCuD",
        "colab_type": "code",
        "outputId": "584a2b1b-2cb2-4ba8-ffcd-e6fef3a4edb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#This function here converts the images to binary - Black and White images\n",
        "def binary_images(train_images):\n",
        "\n",
        "  train_images_binary=np.empty(shape=(train_images.shape))\n",
        "  print(train_images_binary.shape)\n",
        "\n",
        "  for x in range(0,train_images.shape[0]):\n",
        "    image_array=train_images[x]\n",
        "    #print(image_array)\n",
        "    binary=np.where(image_array > 0,1,0)\n",
        "    #print(binary)\n",
        "\n",
        "    train_images_binary[x]=binary\n",
        "    \n",
        "  return train_images_binary\n",
        " \n",
        "\n",
        "#This function adds an extra feature to the binary images\n",
        "#The extra feature is the ratio of number of white pixels to black pixels , later we will add number of white regions in image\n",
        "def number_BW_ratios(train_images):\n",
        "  \n",
        "  train_images_new=np.empty(shape=(train_images.shape[0],785))  #defines new empty array with new feature \n",
        "  \n",
        "  \n",
        "  for index in range(0,train_images.shape[0]):\n",
        "    image=train_images[index]\n",
        "    \n",
        "    #loop for counting black and white pixels\n",
        "    #then calculating ratios\n",
        "    white_pixels=0\n",
        "    black_pixels=0\n",
        "    for pixel in range(0,784):\n",
        "      if (image[pixel]==0):\n",
        "        white_pixels+=1\n",
        "        \n",
        "      else:\n",
        "        black_pixels+=1\n",
        "    #print('White',white_pixels)   \n",
        "    ratio_BW=(white_pixels/black_pixels)#.astype('float32') \n",
        "    #print(ratio_BW)\n",
        "        \n",
        "    extra_feature=ratio_BW\n",
        "    extra_feature/=255\n",
        "    image_new=np.empty(shape=785)\n",
        "    \n",
        "    for x in range(0,784):\n",
        "      image_new[x]=image[x]\n",
        "\n",
        "    image_new[784]=extra_feature\n",
        "    train_images_new[index]=image_new\n",
        "    \n",
        "  return train_images_new\n",
        "\n",
        "\n",
        "#Here we convert images to binary, then calculate the ratio of BW pixels before concatenating with original feature vector\n",
        "train_images_binary=binary_images(train_images)   #send reshaped images here \n",
        "test_images_binary=binary_images(test_images)\n",
        "print('Binary Images',train_images_binary.shape)\n",
        "print(train_images[0][27])\n",
        "\n",
        "#The set of concatenated features images with ratios which will sent to the network for training\n",
        "\n",
        "train_images_new2=number_BW_ratios(train_images_binary)  \n",
        "test_images_new2=number_BW_ratios(test_images_binary)\n",
        "print(test_images_new2.shape)\n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "Binary Images (60000, 784)\n",
            "0\n",
            "(10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B811A14ZVm5p",
        "colab_type": "code",
        "outputId": "760855ec-d7dd-4527-b469-dafb5aaf786c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Defining the Single layered Network\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense((28*28),activation='relu',input_shape=((28*28)+1,)))\n",
        "model.add(layers.Dense(10,activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 784)               616224    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 624,074\n",
            "Trainable params: 624,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lBo2oy46VqeM",
        "colab_type": "code",
        "outputId": "1f412992-7957-4ceb-b360-586c4c9a0d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels_original,10)\n",
        "test_labels = to_categorical(test_labels_original,10)\n",
        "\n",
        "\n",
        "\n",
        "#Compiling the network with Black and white ratio as extra feature\n",
        "\n",
        "epochs=20\n",
        "batch_size=128\n",
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history=model.fit(train_images_new2, train_labels, epochs=epochs,batch_size=batch_size, validation_data=(test_images_new2, test_labels))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.8898 - acc: 0.7971 - val_loss: 0.4873 - val_acc: 0.8809\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.4384 - acc: 0.8838 - val_loss: 0.3781 - val_acc: 0.8976\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.3694 - acc: 0.8977 - val_loss: 0.3376 - val_acc: 0.9075\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.3353 - acc: 0.9052 - val_loss: 0.3108 - val_acc: 0.9125\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.3127 - acc: 0.9110 - val_loss: 0.2953 - val_acc: 0.9166\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.2957 - acc: 0.9156 - val_loss: 0.2797 - val_acc: 0.9209\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.2818 - acc: 0.9193 - val_loss: 0.2675 - val_acc: 0.9237\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.2698 - acc: 0.9226 - val_loss: 0.2576 - val_acc: 0.9251\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.2592 - acc: 0.9260 - val_loss: 0.2494 - val_acc: 0.9280\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 8s 142us/step - loss: 0.2499 - acc: 0.9286 - val_loss: 0.2427 - val_acc: 0.9296\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.2414 - acc: 0.9308 - val_loss: 0.2341 - val_acc: 0.9329\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.2335 - acc: 0.9337 - val_loss: 0.2273 - val_acc: 0.9338\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.2263 - acc: 0.9353 - val_loss: 0.2220 - val_acc: 0.9357\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.2196 - acc: 0.9369 - val_loss: 0.2158 - val_acc: 0.9364\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.2132 - acc: 0.9390 - val_loss: 0.2122 - val_acc: 0.9395\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.2073 - acc: 0.9410 - val_loss: 0.2063 - val_acc: 0.9397\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.2019 - acc: 0.9422 - val_loss: 0.2020 - val_acc: 0.9411\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.1965 - acc: 0.9443 - val_loss: 0.1970 - val_acc: 0.9415\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.1916 - acc: 0.9460 - val_loss: 0.1919 - val_acc: 0.9434\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.1869 - acc: 0.9468 - val_loss: 0.1888 - val_acc: 0.9439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KzTQSrYBGvQQ",
        "colab_type": "code",
        "outputId": "463ccd3a-8c82-4f63-a1e3-5868d4f8357b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#In this part of the code, we will use Connected components algorithm and then classify using \n",
        "#number of white regions per image\n",
        "\n",
        "# A class is defined that will take the image and calculate the connected components using DFS\n",
        "\n",
        "class Connected_components: \n",
        "  \n",
        "    def __init__(self,image, height, width): \n",
        "        self.graph = image\n",
        "        self.height = height \n",
        "        self.width = width \n",
        "        \n",
        "  \n",
        "    def visited(self, i, j, visited): \n",
        "        return (i >= 0 and i < self.height and \n",
        "                j >= 0 and j < self.width and \n",
        "                not visited[i][j] and self.graph[i][j]) \n",
        "              \n",
        "\n",
        "    def DFS(self, i, j, visited): \n",
        "        rowNbr = [-1, -1, -1,  0, 0,  1, 1, 1]; \n",
        "        colNbr = [-1,  0,  1, -1, 1, -1, 0, 1];   \n",
        "        visited[i][j] = True\n",
        "  \n",
        "        #we use 8 neighborhood \n",
        "        for k in range(8): \n",
        "            if self.visited(i + rowNbr[k], j + colNbr[k], visited): \n",
        "                self.DFS(i + rowNbr[k], j + colNbr[k], visited) \n",
        "  \n",
        "\n",
        "    def count_white_regions(self): \n",
        "        visited = [[False for j in range(self.width)]for i in range(self.height)] \n",
        "\n",
        "        count = 0\n",
        "        for i in range(self.height): \n",
        "            for j in range(self.width): \n",
        "                if visited[i][j] == False and self.graph[i][j] ==1: \n",
        "                    self.DFS(i, j, visited) \n",
        "                    count += 1\n",
        "  \n",
        "        return count\n",
        "\n",
        "\n",
        "\n",
        "#get binary images with shape (..,28,28)\n",
        "train_images_binary=binary_images(train_images_original)  \n",
        "test_images_binary=binary_images(test_images_original)\n",
        "\n",
        "\n",
        "#define function that uses the Connected components class above and calculates number of white regions\n",
        "def connected_components(train_images):\n",
        "  \n",
        "  train_images_new=np.empty(shape=(train_images.shape[0],785))  #defines new vector of shape (60000,785) or (10000,785)\n",
        "  \n",
        "  for index in range(0,train_images.shape[0]):\n",
        "    \n",
        "    image=train_images[index]\n",
        "    num_white_regions=Connected_components(image,28, 28).count_white_regions()\n",
        "    extra_feature=num_white_regions\n",
        "    image_new=np.empty(shape=785)\n",
        "    image=train_images[index].reshape(28*28)\n",
        "    \n",
        "    for x in range(0,784):\n",
        "      image_new[x]=image[x]\n",
        "\n",
        "    image_new[784]=extra_feature\n",
        "    train_images_new[index]=image_new\n",
        "    \n",
        "  return train_images_new\n",
        "\n",
        "\n",
        "#This function here adds the extra feature -number of white regions to the original image feature vector \n",
        "def add_feature(train_images):\n",
        "  \n",
        "  train_images_new=np.empty(shape=(train_images.shape[0],785))  #defines new vector of shape (60000,785) or (10000,785)\n",
        "  print('new',train_images_new.shape)\n",
        "  white_region_dict={0:2, 1:1,2:1,3:1,4:1,5:1,6:2,7:1,8:3,9:2}\n",
        "  \n",
        "  for index in range(0,train_images.shape[0]):\n",
        "    image=train_images[index]\n",
        "    image_label=train_labels[index]\n",
        "    #print(image_label)\n",
        "    extra_feature=white_region_dict[image_label]\n",
        "    #print(extra_feature)\n",
        "    image_new=np.empty(shape=785)\n",
        "    \n",
        "    for x in range(0,784):\n",
        "      image_new[x]=image[x]\n",
        "\n",
        "    image_new[784]=extra_feature\n",
        "    #print(image_new)\n",
        "    #print(image_new.shape)\n",
        "    train_images_new[index]=image_new\n",
        "    \n",
        "  return train_images_new\n",
        "\n",
        "\n",
        "#get binary images again\n",
        "train_images_binary1=binary_images(train_images_original)   #send original images here \n",
        "test_images_binary1=binary_images(test_images_original)\n",
        "print('Binary Images',train_images_binary1.shape)\n",
        "print(train_images[0][27])\n",
        "\n",
        "\n",
        "#here we find number of white regions and concatenate\n",
        "\n",
        "train_images_new1=connected_components(train_images_binary1) \n",
        "print(train_images_new1.shape)\n",
        "print(train_images_new1[59000].shape)\n",
        "\n",
        "\n",
        "test_images_new1=connected_components(test_images_binary1) \n",
        "print(test_images_new1.shape)\n",
        "print(test_images_new1[1000].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "Binary Images (60000, 28, 28)\n",
            "0\n",
            "(60000, 785)\n",
            "(785,)\n",
            "(10000, 785)\n",
            "(785,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cBlKngJYVGMt",
        "colab_type": "code",
        "outputId": "24457c97-cd98-47a2-d5cd-42bb2199d295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "# Here we train our classifier using Number of white regions as extra features\n",
        "\n",
        "train_labels1 = to_categorical(train_labels_original,10)\n",
        "test_labels1 = to_categorical(test_labels_original,10)\n",
        "\n",
        "epochs=20\n",
        "batch_size=128\n",
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history=model.fit(train_images_new1, train_labels1, epochs=epochs,batch_size=batch_size, validation_data=(test_images_new1, test_labels1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.1826 - acc: 0.9481 - val_loss: 0.1854 - val_acc: 0.9451\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1783 - acc: 0.9494 - val_loss: 0.1811 - val_acc: 0.9472\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.1743 - acc: 0.9504 - val_loss: 0.1781 - val_acc: 0.9481\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.1704 - acc: 0.9516 - val_loss: 0.1741 - val_acc: 0.9486\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1667 - acc: 0.9524 - val_loss: 0.1711 - val_acc: 0.9501\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1632 - acc: 0.9533 - val_loss: 0.1681 - val_acc: 0.9509\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 10s 158us/step - loss: 0.1598 - acc: 0.9547 - val_loss: 0.1659 - val_acc: 0.9514\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.1566 - acc: 0.9555 - val_loss: 0.1628 - val_acc: 0.9517\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.1535 - acc: 0.9562 - val_loss: 0.1600 - val_acc: 0.9535\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.1505 - acc: 0.9571 - val_loss: 0.1580 - val_acc: 0.9541\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1476 - acc: 0.9580 - val_loss: 0.1561 - val_acc: 0.9544\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.1449 - acc: 0.9593 - val_loss: 0.1533 - val_acc: 0.9551\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.1422 - acc: 0.9596 - val_loss: 0.1509 - val_acc: 0.9556\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.1397 - acc: 0.9607 - val_loss: 0.1486 - val_acc: 0.9565\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.1372 - acc: 0.9616 - val_loss: 0.1467 - val_acc: 0.9575\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.1349 - acc: 0.9623 - val_loss: 0.1453 - val_acc: 0.9579\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.1325 - acc: 0.9630 - val_loss: 0.1435 - val_acc: 0.9587\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1303 - acc: 0.9638 - val_loss: 0.1409 - val_acc: 0.9597\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.1281 - acc: 0.9643 - val_loss: 0.1400 - val_acc: 0.9605\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.1260 - acc: 0.9650 - val_loss: 0.1381 - val_acc: 0.9607\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}